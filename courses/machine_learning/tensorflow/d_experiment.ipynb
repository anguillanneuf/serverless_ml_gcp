{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 2d. Distributed training and monitoring </h1>\n",
    "\n",
    "In this notebook, we refactor to use the Experimenter class instead of hand-coding our ML pipeline. This allows us to carry out evaluation as part of our training loop instead of as a separate step. It also adds in failure-handling that is necessary for distributed training capabilities.\n",
    "\n",
    "We also use TensorBoard to monitor the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.1\n"
     ]
    }
   ],
   "source": [
    "import google.datalab.ml as ml\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import layers\n",
    "print tf.__version__\n",
    "# print ml.sdk_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datalab.bigquery as bq\n",
    "import numpy as np\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Input </h2>\n",
    "\n",
    "Read data created in Lab1a, but this time make it more general, so that we are reading in batches.  Instead of using Pandas, we will use add a filename queue to the TensorFlow graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CSV_COLUMNS = ['fare_amount', 'pickuplon','pickuplat','dropofflon','dropofflat','passengers', 'key']\n",
    "LABEL_COLUMN = 'fare_amount'\n",
    "DEFAULTS = [[0.0], [-74.0], [40.0], [-74.0], [40.7], [1.0], ['nokey']]\n",
    "\n",
    "def read_dataset(filename, num_epochs=None, batch_size=512, mode=tf.contrib.learn.ModeKeys.TRAIN):\n",
    "  def _input_fn():\n",
    "    filename_queue = tf.train.string_input_producer(\n",
    "        [filename], num_epochs=num_epochs, shuffle=True)\n",
    "    reader = tf.TextLineReader()\n",
    "    _, value = reader.read_up_to(filename_queue, num_records=batch_size)\n",
    "\n",
    "    value_column = tf.expand_dims(value, -1)\n",
    "    columns = tf.decode_csv(value_column, record_defaults=DEFAULTS)\n",
    "    features = dict(zip(CSV_COLUMNS, columns))\n",
    "    label = features.pop(LABEL_COLUMN)\n",
    "    return features, label\n",
    "\n",
    "  return _input_fn\n",
    "\n",
    "def get_train():\n",
    "  return read_dataset('./taxi-train.csv', num_epochs=100, mode=tf.contrib.learn.ModeKeys.TRAIN)\n",
    "\n",
    "def get_valid():\n",
    "  return read_dataset('./taxi-valid.csv', num_epochs=1, mode=tf.contrib.learn.ModeKeys.EVAL)\n",
    "\n",
    "def get_test():\n",
    "  return read_dataset('./taxi-test.csv', num_epochs=1, mode=tf.contrib.learn.ModeKeys.EVAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Create features out of input data </h2>\n",
    "\n",
    "For now, pass these through.  (same as previous lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "INPUT_COLUMNS = [\n",
    "    layers.real_valued_column('pickuplon'),\n",
    "    layers.real_valued_column('pickuplat'),\n",
    "    layers.real_valued_column('dropofflat'),\n",
    "    layers.real_valued_column('dropofflon'),\n",
    "    layers.real_valued_column('passengers'),\n",
    "]\n",
    "\n",
    "feature_cols = INPUT_COLUMNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Experiment framework </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "[2018-02-12 19:35:55,126] {tf_logging.py:82} INFO - Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f00bcc5c6d0>, '_model_dir': 'taxi_trained', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_tf_random_seed': None, '_save_summary_steps': 100, '_environment': 'local', '_num_worker_replicas': 0, '_task_id': 0, '_log_step_count_steps': 100, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_evaluation_master': '', '_master': ''}\n",
      "[2018-02-12 19:35:55,133] {tf_logging.py:82} INFO - Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f00bcc5c6d0>, '_model_dir': 'taxi_trained', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_tf_random_seed': None, '_save_summary_steps': 100, '_environment': 'local', '_num_worker_replicas': 0, '_task_id': 0, '_log_step_count_steps': 100, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_evaluation_master': '', '_master': ''}\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:267: __init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "[2018-02-12 19:35:55,732] {tf_logging.py:90} WARNING - From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:267: __init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/linear.py:173: get_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_global_step\n",
      "[2018-02-12 19:35:55,907] {tf_logging.py:90} WARNING - From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/linear.py:173: get_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_global_step\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "[2018-02-12 19:35:56,028] {tf_logging.py:82} INFO - Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into taxi_trained/model.ckpt.\n",
      "[2018-02-12 19:35:56,602] {tf_logging.py:82} INFO - Saving checkpoints for 1 into taxi_trained/model.ckpt.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-12-19:35:56\n",
      "[2018-02-12 19:35:56,798] {tf_logging.py:82} INFO - Starting evaluation at 2018-02-12-19:35:56\n",
      "INFO:tensorflow:Restoring parameters from taxi_trained/model.ckpt-1\n",
      "[2018-02-12 19:35:57,077] {tf_logging.py:82} INFO - Restoring parameters from taxi_trained/model.ckpt-1\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "[2018-02-12 19:35:57,153] {tf_logging.py:82} INFO - Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "[2018-02-12 19:35:57,168] {tf_logging.py:82} INFO - Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "[2018-02-12 19:35:57,184] {tf_logging.py:82} INFO - Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "[2018-02-12 19:35:57,198] {tf_logging.py:82} INFO - Evaluation [4/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-12-19:35:57\n",
      "[2018-02-12 19:35:57,209] {tf_logging.py:82} INFO - Finished evaluation at 2018-02-12-19:35:57\n",
      "INFO:tensorflow:Saving dict for global step 1: global_step = 1, loss = 1325.1002, rmse = 36.276543\n",
      "[2018-02-12 19:35:57,214] {tf_logging.py:82} INFO - Saving dict for global step 1: global_step = 1, loss = 1325.1002, rmse = 36.276543\n",
      "INFO:tensorflow:Validation (step 1): loss = 1325.1002, global_step = 1, rmse = 36.276543\n",
      "[2018-02-12 19:35:57,278] {tf_logging.py:82} INFO - Validation (step 1): loss = 1325.1002, global_step = 1, rmse = 36.276543\n",
      "INFO:tensorflow:loss = 177.42944, step = 1\n",
      "[2018-02-12 19:35:57,285] {tf_logging.py:82} INFO - loss = 177.42944, step = 1\n",
      "INFO:tensorflow:global_step/sec: 56.7099\n",
      "[2018-02-12 19:35:58,437] {tf_logging.py:82} INFO - global_step/sec: 56.7099\n",
      "INFO:tensorflow:loss = 82.089645, step = 101 (1.162 sec)\n",
      "[2018-02-12 19:35:58,447] {tf_logging.py:82} INFO - loss = 82.089645, step = 101 (1.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.0654\n",
      "[2018-02-12 19:35:59,489] {tf_logging.py:82} INFO - global_step/sec: 95.0654\n",
      "INFO:tensorflow:loss = 90.56337, step = 201 (1.060 sec)\n",
      "[2018-02-12 19:35:59,507] {tf_logging.py:82} INFO - loss = 90.56337, step = 201 (1.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.7366\n",
      "[2018-02-12 19:36:00,579] {tf_logging.py:82} INFO - global_step/sec: 91.7366\n",
      "INFO:tensorflow:loss = 91.36656, step = 301 (1.083 sec)\n",
      "[2018-02-12 19:36:00,590] {tf_logging.py:82} INFO - loss = 91.36656, step = 301 (1.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.4801\n",
      "[2018-02-12 19:36:01,672] {tf_logging.py:82} INFO - global_step/sec: 91.4801\n",
      "INFO:tensorflow:loss = 65.89668, step = 401 (1.096 sec)\n",
      "[2018-02-12 19:36:01,686] {tf_logging.py:82} INFO - loss = 65.89668, step = 401 (1.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.139\n",
      "[2018-02-12 19:36:02,861] {tf_logging.py:82} INFO - global_step/sec: 84.139\n",
      "INFO:tensorflow:loss = 82.090485, step = 501 (1.186 sec)\n",
      "[2018-02-12 19:36:02,872] {tf_logging.py:82} INFO - loss = 82.090485, step = 501 (1.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.4392\n",
      "[2018-02-12 19:36:04,004] {tf_logging.py:82} INFO - global_step/sec: 87.4392\n",
      "INFO:tensorflow:loss = 90.52634, step = 601 (1.144 sec)\n",
      "[2018-02-12 19:36:04,016] {tf_logging.py:82} INFO - loss = 90.52634, step = 601 (1.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.1717\n",
      "[2018-02-12 19:36:05,252] {tf_logging.py:82} INFO - global_step/sec: 80.1717\n",
      "INFO:tensorflow:loss = 91.30771, step = 701 (1.247 sec)\n",
      "[2018-02-12 19:36:05,263] {tf_logging.py:82} INFO - loss = 91.30771, step = 701 (1.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.7231\n",
      "[2018-02-12 19:36:06,319] {tf_logging.py:82} INFO - global_step/sec: 93.7231\n",
      "INFO:tensorflow:loss = 65.58356, step = 801 (1.066 sec)\n",
      "[2018-02-12 19:36:06,329] {tf_logging.py:82} INFO - loss = 65.58356, step = 801 (1.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.1951\n",
      "[2018-02-12 19:36:07,466] {tf_logging.py:82} INFO - global_step/sec: 87.1951\n",
      "INFO:tensorflow:loss = 82.09163, step = 901 (1.148 sec)\n",
      "[2018-02-12 19:36:07,478] {tf_logging.py:82} INFO - loss = 82.09163, step = 901 (1.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.2605\n",
      "[2018-02-12 19:36:08,586] {tf_logging.py:82} INFO - global_step/sec: 89.2605\n",
      "INFO:tensorflow:loss = 90.510475, step = 1001 (1.118 sec)\n",
      "[2018-02-12 19:36:08,596] {tf_logging.py:82} INFO - loss = 90.510475, step = 1001 (1.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.3244\n",
      "[2018-02-12 19:36:09,731] {tf_logging.py:82} INFO - global_step/sec: 87.3244\n",
      "INFO:tensorflow:loss = 91.27123, step = 1101 (1.146 sec)\n",
      "[2018-02-12 19:36:09,742] {tf_logging.py:82} INFO - loss = 91.27123, step = 1101 (1.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.447\n",
      "[2018-02-12 19:36:10,849] {tf_logging.py:82} INFO - global_step/sec: 89.447\n",
      "INFO:tensorflow:loss = 65.357895, step = 1201 (1.117 sec)\n",
      "[2018-02-12 19:36:10,859] {tf_logging.py:82} INFO - loss = 65.357895, step = 1201 (1.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.5101\n",
      "[2018-02-12 19:36:11,992] {tf_logging.py:82} INFO - global_step/sec: 87.5101\n",
      "INFO:tensorflow:loss = 82.09177, step = 1301 (1.148 sec)\n",
      "[2018-02-12 19:36:12,007] {tf_logging.py:82} INFO - loss = 82.09177, step = 1301 (1.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.8423\n",
      "[2018-02-12 19:36:13,276] {tf_logging.py:82} INFO - global_step/sec: 77.8423\n",
      "INFO:tensorflow:loss = 90.50412, step = 1401 (1.284 sec)\n",
      "[2018-02-12 19:36:13,290] {tf_logging.py:82} INFO - loss = 90.50412, step = 1401 (1.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.3681\n",
      "[2018-02-12 19:36:14,476] {tf_logging.py:82} INFO - global_step/sec: 83.3681\n",
      "INFO:tensorflow:loss = 91.24715, step = 1501 (1.197 sec)\n",
      "[2018-02-12 19:36:14,487] {tf_logging.py:82} INFO - loss = 91.24715, step = 1501 (1.197 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1600 into taxi_trained/model.ckpt.\n",
      "[2018-02-12 19:36:15,519] {tf_logging.py:82} INFO - Saving checkpoints for 1600 into taxi_trained/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 109.05836.\n",
      "[2018-02-12 19:36:15,583] {tf_logging.py:82} INFO - Loss for final step: 109.05836.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-12-19:36:15\n",
      "[2018-02-12 19:36:15,686] {tf_logging.py:82} INFO - Starting evaluation at 2018-02-12-19:36:15\n",
      "INFO:tensorflow:Restoring parameters from taxi_trained/model.ckpt-1600\n",
      "[2018-02-12 19:36:15,773] {tf_logging.py:82} INFO - Restoring parameters from taxi_trained/model.ckpt-1600\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "[2018-02-12 19:36:15,858] {tf_logging.py:82} INFO - Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "[2018-02-12 19:36:15,873] {tf_logging.py:82} INFO - Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "[2018-02-12 19:36:15,888] {tf_logging.py:82} INFO - Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "[2018-02-12 19:36:15,897] {tf_logging.py:82} INFO - Evaluation [4/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-12-19:36:15\n",
      "[2018-02-12 19:36:15,909] {tf_logging.py:82} INFO - Finished evaluation at 2018-02-12-19:36:15\n",
      "INFO:tensorflow:Saving dict for global step 1600: global_step = 1600, loss = 91.18565, rmse = 9.460671\n",
      "[2018-02-12 19:36:15,914] {tf_logging.py:82} INFO - Saving dict for global step 1600: global_step = 1600, loss = 91.18565, rmse = 9.460671\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'global_step': 1600, 'loss': 91.18565, 'rmse': 9.460671}, [])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow.contrib.learn as tflearn\n",
    "from tensorflow.contrib.learn.python.learn import learn_runner\n",
    "import tensorflow.contrib.metrics as metrics\n",
    "\n",
    "def experiment_fn(output_dir):\n",
    "    return tflearn.Experiment(\n",
    "        tflearn.LinearRegressor(feature_columns=feature_cols, model_dir=output_dir),\n",
    "        train_input_fn=get_train(),\n",
    "        eval_input_fn=get_valid(),\n",
    "        eval_metrics={\n",
    "            'rmse': tflearn.MetricSpec(\n",
    "                metric_fn=metrics.streaming_root_mean_squared_error\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "shutil.rmtree('taxi_trained', ignore_errors=True) # start fresh each time\n",
    "learn_runner.run(experiment_fn, 'taxi_trained')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Monitoring with TensorBoard </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>TensorBoard was started successfully with pid 12384. Click <a href=\"/_proxy/55566/\" target=\"_blank\">here</a> to access it.</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logdir</th>\n",
       "      <th>pid</th>\n",
       "      <th>port</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./taxi_trained</td>\n",
       "      <td>12382</td>\n",
       "      <td>41737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./taxi_trained</td>\n",
       "      <td>12384</td>\n",
       "      <td>55566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           logdir    pid   port\n",
       "0  ./taxi_trained  12382  41737\n",
       "1  ./taxi_trained  12384  55566"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.datalab.ml import TensorBoard\n",
    "TensorBoard().start('./taxi_trained')\n",
    "TensorBoard().list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stopped TensorBoard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logdir</th>\n",
       "      <th>pid</th>\n",
       "      <th>port</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./taxi_trained</td>\n",
       "      <td>12382</td>\n",
       "      <td>41737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./taxi_trained</td>\n",
       "      <td>12384</td>\n",
       "      <td>55566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           logdir    pid   port\n",
       "0  ./taxi_trained  12382  41737\n",
       "1  ./taxi_trained  12384  55566"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to stop TensorBoard\n",
    "TensorBoard().stop(23002)\n",
    "print 'stopped TensorBoard'\n",
    "TensorBoard().list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2017 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
