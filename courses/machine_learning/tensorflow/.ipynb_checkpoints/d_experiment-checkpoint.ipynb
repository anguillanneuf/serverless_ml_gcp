{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 2d. Distributed training and monitoring </h1>\n",
    "\n",
    "In this notebook, we refactor to use the Experimenter class instead of hand-coding our ML pipeline. This allows us to carry out evaluation as part of our training loop instead of as a separate step. It also adds in failure-handling that is necessary for distributed training capabilities.\n",
    "\n",
    "We also use TensorBoard to monitor the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.1\n"
     ]
    }
   ],
   "source": [
    "import google.datalab.ml as ml\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import layers\n",
    "print tf.__version__\n",
    "# print ml.sdk_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datalab.bigquery as bq\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Input </h2>\n",
    "\n",
    "Read data created in Lab1a, but this time make it more general, so that we are reading in batches.  Instead of using Pandas, we will use add a filename queue to the TensorFlow graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CSV_COLUMNS = ['fare_amount', 'pickuplon','pickuplat','dropofflon','dropofflat','passengers', 'key']\n",
    "LABEL_COLUMN = 'fare_amount'\n",
    "DEFAULTS = [[0.0], [-74.0], [40.0], [-74.0], [40.7], [1.0], ['nokey']]\n",
    "\n",
    "def read_dataset(filename, num_epochs=None, batch_size=512, mode=tf.contrib.learn.ModeKeys.TRAIN):\n",
    "  def _input_fn():\n",
    "    filename_queue = tf.train.string_input_producer(\n",
    "        [filename], num_epochs=num_epochs, shuffle=True)\n",
    "    reader = tf.TextLineReader()\n",
    "    _, value = reader.read_up_to(filename_queue, num_records=batch_size)\n",
    "\n",
    "    value_column = tf.expand_dims(value, -1)\n",
    "    columns = tf.decode_csv(value_column, record_defaults=DEFAULTS)\n",
    "    features = dict(zip(CSV_COLUMNS, columns))\n",
    "    label = features.pop(LABEL_COLUMN)\n",
    "    return features, label\n",
    "\n",
    "  return _input_fn\n",
    "\n",
    "def get_train():\n",
    "  return read_dataset('./taxi-train.csv', num_epochs=100, mode=tf.contrib.learn.ModeKeys.TRAIN)\n",
    "\n",
    "def get_valid():\n",
    "  return read_dataset('./taxi-valid.csv', num_epochs=1, mode=tf.contrib.learn.ModeKeys.EVAL)\n",
    "\n",
    "def get_test():\n",
    "  return read_dataset('./taxi-test.csv', num_epochs=1, mode=tf.contrib.learn.ModeKeys.EVAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Create features out of input data </h2>\n",
    "\n",
    "For now, pass these through.  (same as previous lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "INPUT_COLUMNS = [\n",
    "    layers.real_valued_column('pickuplon'),\n",
    "    layers.real_valued_column('pickuplat'),\n",
    "    layers.real_valued_column('dropofflat'),\n",
    "    layers.real_valued_column('dropofflon'),\n",
    "    layers.real_valued_column('passengers'),\n",
    "]\n",
    "\n",
    "feature_cols = INPUT_COLUMNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Experiment framework </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "[2018-01-22 20:47:54,930] {tf_logging.py:82} INFO - Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe7b5b560d0>, '_model_dir': 'taxi_trained', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_tf_random_seed': None, '_save_summary_steps': 100, '_environment': 'local', '_num_worker_replicas': 0, '_task_id': 0, '_log_step_count_steps': 100, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_evaluation_master': '', '_master': ''}\n",
      "[2018-01-22 20:47:54,935] {tf_logging.py:82} INFO - Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe7b5b560d0>, '_model_dir': 'taxi_trained', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_tf_random_seed': None, '_save_summary_steps': 100, '_environment': 'local', '_num_worker_replicas': 0, '_task_id': 0, '_log_step_count_steps': 100, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_evaluation_master': '', '_master': ''}\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:267: __init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "[2018-01-22 20:47:55,545] {tf_logging.py:90} WARNING - From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:267: __init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/linear.py:173: get_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_global_step\n",
      "[2018-01-22 20:47:55,666] {tf_logging.py:90} WARNING - From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/linear.py:173: get_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_global_step\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "[2018-01-22 20:47:55,778] {tf_logging.py:82} INFO - Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into taxi_trained/model.ckpt.\n",
      "[2018-01-22 20:47:56,282] {tf_logging.py:82} INFO - Saving checkpoints for 1 into taxi_trained/model.ckpt.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-22-20:47:56\n",
      "[2018-01-22 20:47:56,472] {tf_logging.py:82} INFO - Starting evaluation at 2018-01-22-20:47:56\n",
      "INFO:tensorflow:Restoring parameters from taxi_trained/model.ckpt-1\n",
      "[2018-01-22 20:47:56,750] {tf_logging.py:82} INFO - Restoring parameters from taxi_trained/model.ckpt-1\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "[2018-01-22 20:47:56,824] {tf_logging.py:82} INFO - Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "[2018-01-22 20:47:56,838] {tf_logging.py:82} INFO - Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "[2018-01-22 20:47:56,851] {tf_logging.py:82} INFO - Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "[2018-01-22 20:47:56,859] {tf_logging.py:82} INFO - Evaluation [4/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-22-20:47:56\n",
      "[2018-01-22 20:47:56,871] {tf_logging.py:82} INFO - Finished evaluation at 2018-01-22-20:47:56\n",
      "INFO:tensorflow:Saving dict for global step 1: global_step = 1, loss = 1325.1002, rmse = 36.276543\n",
      "[2018-01-22 20:47:56,876] {tf_logging.py:82} INFO - Saving dict for global step 1: global_step = 1, loss = 1325.1002, rmse = 36.276543\n",
      "INFO:tensorflow:Validation (step 1): loss = 1325.1002, global_step = 1, rmse = 36.276543\n",
      "[2018-01-22 20:47:56,929] {tf_logging.py:82} INFO - Validation (step 1): loss = 1325.1002, global_step = 1, rmse = 36.276543\n",
      "INFO:tensorflow:loss = 177.42944, step = 1\n",
      "[2018-01-22 20:47:56,935] {tf_logging.py:82} INFO - loss = 177.42944, step = 1\n",
      "INFO:tensorflow:global_step/sec: 53.9393\n",
      "[2018-01-22 20:47:58,221] {tf_logging.py:82} INFO - global_step/sec: 53.9393\n",
      "INFO:tensorflow:loss = 82.089645, step = 101 (1.299 sec)\n",
      "[2018-01-22 20:47:58,234] {tf_logging.py:82} INFO - loss = 82.089645, step = 101 (1.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.7743\n",
      "[2018-01-22 20:47:59,386] {tf_logging.py:82} INFO - global_step/sec: 85.7743\n",
      "INFO:tensorflow:loss = 90.56337, step = 201 (1.163 sec)\n",
      "[2018-01-22 20:47:59,396] {tf_logging.py:82} INFO - loss = 90.56337, step = 201 (1.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.5929\n",
      "[2018-01-22 20:48:00,444] {tf_logging.py:82} INFO - global_step/sec: 94.5929\n",
      "INFO:tensorflow:loss = 91.36656, step = 301 (1.057 sec)\n",
      "[2018-01-22 20:48:00,453] {tf_logging.py:82} INFO - loss = 91.36656, step = 301 (1.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.3057\n",
      "[2018-01-22 20:48:01,515] {tf_logging.py:82} INFO - global_step/sec: 93.3057\n",
      "INFO:tensorflow:loss = 65.89668, step = 401 (1.073 sec)\n",
      "[2018-01-22 20:48:01,526] {tf_logging.py:82} INFO - loss = 65.89668, step = 401 (1.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.2788\n",
      "[2018-01-22 20:48:02,565] {tf_logging.py:82} INFO - global_step/sec: 95.2788\n",
      "INFO:tensorflow:loss = 82.090485, step = 501 (1.048 sec)\n",
      "[2018-01-22 20:48:02,575] {tf_logging.py:82} INFO - loss = 82.090485, step = 501 (1.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 92.3555\n",
      "[2018-01-22 20:48:03,648] {tf_logging.py:82} INFO - global_step/sec: 92.3555\n",
      "INFO:tensorflow:loss = 90.52634, step = 601 (1.083 sec)\n",
      "[2018-01-22 20:48:03,658] {tf_logging.py:82} INFO - loss = 90.52634, step = 601 (1.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.8341\n",
      "[2018-01-22 20:48:04,714] {tf_logging.py:82} INFO - global_step/sec: 93.8341\n",
      "INFO:tensorflow:loss = 91.30771, step = 701 (1.067 sec)\n",
      "[2018-01-22 20:48:04,725] {tf_logging.py:82} INFO - loss = 91.30771, step = 701 (1.067 sec)\n",
      "INFO:tensorflow:global_step/sec: 92.4997\n",
      "[2018-01-22 20:48:05,795] {tf_logging.py:82} INFO - global_step/sec: 92.4997\n",
      "INFO:tensorflow:loss = 65.58356, step = 801 (1.080 sec)\n",
      "[2018-01-22 20:48:05,805] {tf_logging.py:82} INFO - loss = 65.58356, step = 801 (1.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.2212\n",
      "[2018-01-22 20:48:06,954] {tf_logging.py:82} INFO - global_step/sec: 86.2212\n",
      "INFO:tensorflow:loss = 82.09163, step = 901 (1.161 sec)\n",
      "[2018-01-22 20:48:06,966] {tf_logging.py:82} INFO - loss = 82.09163, step = 901 (1.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.4023\n",
      "[2018-01-22 20:48:08,025] {tf_logging.py:82} INFO - global_step/sec: 93.4023\n",
      "INFO:tensorflow:loss = 90.510475, step = 1001 (1.069 sec)\n",
      "[2018-01-22 20:48:08,035] {tf_logging.py:82} INFO - loss = 90.510475, step = 1001 (1.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.462\n",
      "[2018-01-22 20:48:09,283] {tf_logging.py:82} INFO - global_step/sec: 79.462\n",
      "INFO:tensorflow:loss = 91.27123, step = 1101 (1.258 sec)\n",
      "[2018-01-22 20:48:09,293] {tf_logging.py:82} INFO - loss = 91.27123, step = 1101 (1.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.3908\n",
      "[2018-01-22 20:48:10,354] {tf_logging.py:82} INFO - global_step/sec: 93.3908\n",
      "INFO:tensorflow:loss = 65.357895, step = 1201 (1.072 sec)\n",
      "[2018-01-22 20:48:10,365] {tf_logging.py:82} INFO - loss = 65.357895, step = 1201 (1.072 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.8149\n",
      "[2018-01-22 20:48:11,455] {tf_logging.py:82} INFO - global_step/sec: 90.8149\n",
      "INFO:tensorflow:loss = 82.09177, step = 1301 (1.100 sec)\n",
      "[2018-01-22 20:48:11,465] {tf_logging.py:82} INFO - loss = 82.09177, step = 1301 (1.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.2723\n",
      "[2018-01-22 20:48:12,527] {tf_logging.py:82} INFO - global_step/sec: 93.2723\n",
      "INFO:tensorflow:loss = 90.50412, step = 1401 (1.074 sec)\n",
      "[2018-01-22 20:48:12,539] {tf_logging.py:82} INFO - loss = 90.50412, step = 1401 (1.074 sec)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.contrib.learn as tflearn\n",
    "from tensorflow.contrib.learn.python.learn import learn_runner\n",
    "import tensorflow.contrib.metrics as metrics\n",
    "\n",
    "def experiment_fn(output_dir):\n",
    "    return tflearn.Experiment(\n",
    "        tflearn.LinearRegressor(feature_columns=feature_cols, model_dir=output_dir),\n",
    "        train_input_fn=get_train(),\n",
    "        eval_input_fn=get_valid(),\n",
    "        eval_metrics={\n",
    "            'rmse': tflearn.MetricSpec(\n",
    "                metric_fn=metrics.streaming_root_mean_squared_error\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "shutil.rmtree('taxi_trained', ignore_errors=True) # start fresh each time\n",
    "learn_runner.run(experiment_fn, 'taxi_trained')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Monitoring with TensorBoard </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from google.datalab.ml import TensorBoard\n",
    "TensorBoard().start('./taxi_trained')\n",
    "TensorBoard().list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# to stop TensorBoard\n",
    "TensorBoard().stop(23002)\n",
    "print 'stopped TensorBoard'\n",
    "TensorBoard().list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2017 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
